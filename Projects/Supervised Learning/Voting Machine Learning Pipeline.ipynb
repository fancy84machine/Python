{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imputing missing data in a ML Pipeline \n",
    "\n",
    "'''\n",
    "There are many steps to building a model, from creating training and test sets, to fitting a classifier or regressor, to tuning its parameters, to evaluating its performance on new data. \n",
    "Imputation can be seen as the first step of this machine learning process, the entirety of which can be viewed within the context of a pipeline. \n",
    "Scikit-learn provides a pipeline constructor that allows you to piece together these steps into one process and thereby simplify your workflow.\n",
    "What makes pipelines so incredibly useful is the simple interface that they provide. You can use the .fit() and .predict() methods on pipelines \n",
    " \n",
    "'''\n",
    "\n",
    "# Import modules\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report \n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv ('house-votes-84.data', delimiter = ',', header=None, names = ['party', 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16] )\n",
    "for i in range (1, 17):\n",
    "    df[i].replace ( to_replace = ['?'], value = df[i].mode().iloc[0], inplace = True)\n",
    "    df[i] = LabelEncoder().fit_transform (df[i])\n",
    "    \n",
    "# Create arrays for the features and the response variable\n",
    "y = df['party']\n",
    "X = df.drop('party', axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "   democrat       0.99      0.96      0.98        85\n",
      " republican       0.94      0.98      0.96        46\n",
      "\n",
      "avg / total       0.97      0.97      0.97       131\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Setup the Imputation transformer to impute missing data (represented as 'NaN') with the 'most_frequent' value in the column (axis=0).\n",
    "imp = Imputer(missing_values='NaN', strategy='most_frequent', axis=0)\n",
    "\n",
    "# Instantiate the SVC classifier: clf\n",
    "clf = SVC()\n",
    "\n",
    "# Setup the pipeline with the required steps: steps\n",
    "steps = [('imputation', Imputer(missing_values='NaN', strategy='most_frequent', axis=0)),\n",
    "        ('SVM', SVC())]\n",
    "\n",
    "\n",
    "# Create the pipeline: pipeline\n",
    "pipeline = Pipeline(steps)\n",
    "\n",
    "# Create training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Fit the pipeline to the train set\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Predict the labels of the test set\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# Compute metrics\n",
    "print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
